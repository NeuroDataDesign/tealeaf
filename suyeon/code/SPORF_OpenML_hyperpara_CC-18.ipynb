{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenML CC-18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "import sklearn\n",
    "from rerf.rerfClassifier import rerfClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "import math\n",
    "from math import log\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "benchmark_suite = openml.study.get_suite('OpenML-CC18')  # obtain the benchmark suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_optimization_grid(X, y, *argv):\n",
    "    \"\"\"\n",
    "    Given a classifier and a dictionary of hyperparameters, find optimal hyperparameters using GridSearchCV.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy.ndarray\n",
    "        Input data, shape (n_samples, n_features)\n",
    "    y : numpy.ndarray\n",
    "        Output data, shape (n_samples, n_outputs)\n",
    "    *argv : list of tuples (classifier, hyperparameters)\n",
    "        List of (classifier, hyperparameters) tuples:\n",
    "        classifier : sklearn-compliant classifier\n",
    "            For example sklearn.ensemble.RandomForestRegressor, rerf.rerfClassifier, etc\n",
    "        hyperparameters : dictionary of hyperparameter ranges\n",
    "            See https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html.\n",
    "    Returns\n",
    "    -------\n",
    "    clf_best_params : dictionary\n",
    "        Dictionary of best hyperparameters\n",
    "    \"\"\"\n",
    "\n",
    "    clf_best_params = {}\n",
    "\n",
    "    # Iterate over all (classifier, hyperparameters) pairs\n",
    "    for clf, params in argv:\n",
    "\n",
    "        # Run grid search\n",
    "        grid_search = GridSearchCV(\n",
    "            clf, param_grid=params, cv=10, iid=False\n",
    "        )\n",
    "        grid_search.fit(X, y)\n",
    "\n",
    "        # Save results\n",
    "        clf_best_params[clf] = grid_search.best_params_\n",
    "\n",
    "    return clf_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find optimized hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{rerfClassifier(feature_combinations=1.5, image_height=None, image_width=None,\n",
      "               max_depth=None, max_features='auto', min_samples_split=1,\n",
      "               n_estimators=100, n_jobs=None, oob_score=False,\n",
      "               patch_height_max=None, patch_height_min=1, patch_width_max=None,\n",
      "               patch_width_min=1, projection_matrix='RerF', random_state=None): {'n_estimators': 100}}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fc77eaea358e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mclf_best_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperparameter_optimization_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_CC18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_CC18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_best_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mbest_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_best_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data set: %s: '\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "dimen_CC18 = []\n",
    "best_params = []\n",
    "\n",
    "for task_id in benchmark_suite.tasks[47:49]:  # iterate over all tasks\n",
    "#     try:\n",
    "        f = open(\"SPORF_accuracies_CC-18_hyperpara.txt\",\"a\")\n",
    "        task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "        X_CC18, y_CC18 = task.get_X_and_y()  # get the data\n",
    "        dimen_CC18.append(np.shape(X_CC18))\n",
    "        n_features = np.shape(X_CC18)[1]\n",
    "        n_samples = np.shape(X_CC18)[0]\n",
    "\n",
    "        # build a classifier\n",
    "        clf = rerfClassifier(n_estimators=100)\n",
    "        \n",
    "        #specify max_depth and min_sample_splits ranges\n",
    "        max_depth_array = (np.unique(np.round((np.arange(2,math.log(n_samples),\n",
    "                            (math.log(n_samples)-2)/10))))).astype(int)\n",
    "        max_depth_range = np.append(max_depth_array, None)\n",
    "\n",
    "        min_sample_splits_range = (np.unique(np.round((np.arange(1,math.log(n_samples),\n",
    "                                    (math.log(n_samples)-2)/10))))).astype(int)\n",
    "\n",
    "        # specify parameters and distributions to sample from\n",
    "        param_dist = {\"n_estimators\": np.arange(100,550,25)}\n",
    "        \n",
    "        clf_best_params = hyperparameter_optimization_grid(X_CC18, y_CC18, (clf, param_dist))\n",
    "        print(clf_best_params)\n",
    "        best_params.append(clf_best_params[0], axis = 0)\n",
    "        print(task_id)\n",
    "        print('Data set: %s: ' % (task.get_dataset().name))\n",
    "        print(clf_best_params)\n",
    "        print('Time: '+ str(datetime.now() - startTime))\n",
    "        f.write('%i,%s,%s,%f,%f,%f,%f,%f\\n' % (task_id,task.get_dataset().name,str(datetime.now() - startTime),clf_best_params[0]))\n",
    "        f.close()\n",
    "#     except:\n",
    "#         print('Error in OpenML CC-18 dataset ' + str(task_id))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SPORF with optimized hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clf = sklearn.pipeline.make_pipeline(sklearn.preprocessing.Imputer(), rerfClassifier())\n",
    "\n",
    "# for task_id in benchmark_suite.tasks[68:]:  # iterate over all tasks\n",
    "#     try:\n",
    "#         f = open(\"SPORF_accuracies_CC-18.txt\",\"a\")\n",
    "#         startTime = datetime.now()\n",
    "#         task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "#         openml.config.apikey = '204cdba18d110fd68ad24b131ea92030'  # set the OpenML Api Key\n",
    "#         run = openml.runs.run_model_on_task(clf, task)  # run the classifier on the task\n",
    "#         score = run.get_metric_fn(sklearn.metrics.accuracy_score)  # print accuracy score\n",
    "#         print(task_id)\n",
    "#         print('Data set: %s; Accuracy: %0.4f' % (task.get_dataset().name,score.mean()))\n",
    "#         print('Time: '+ str(datetime.now() - startTime))\n",
    "#         f.write('%i,%s,%0.4f,%s\\n' % (task_id,task.get_dataset().name,score.mean(),str(datetime.now() - startTime)))\n",
    "#         f.close()\n",
    "#     except:\n",
    "#         print('Error in' + str(task_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tealeaf] *",
   "language": "python",
   "name": "conda-env-tealeaf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
