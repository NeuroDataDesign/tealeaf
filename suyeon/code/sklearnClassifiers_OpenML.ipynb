{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set: kr-vs-kp; Accuracy: 1.00\n",
      "Data set: letter; Accuracy: 0.88\n",
      "Data set: balance-scale; Accuracy: 0.77\n",
      "Data set: mfeat-factors; Accuracy: 0.89\n",
      "Data set: mfeat-fourier; Accuracy: 0.76\n",
      "Data set: breast-w; Accuracy: 0.95\n",
      "Data set: mfeat-karhunen; Accuracy: 0.82\n",
      "Data set: mfeat-morphological; Accuracy: 0.65\n",
      "Data set: mfeat-zernike; Accuracy: 0.67\n",
      "Data set: cmc; Accuracy: 0.48\n"
     ]
    }
   ],
   "source": [
    "import openml\n",
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "benchmark_suite = openml.study.get_suite('OpenML-CC18')  # obtain the benchmark suite\n",
    "\n",
    "# build a scikit-learn classifier\n",
    "clf = sklearn.pipeline.make_pipeline(sklearn.preprocessing.Imputer(), DecisionTreeClassifier())\n",
    "\n",
    "for task_id in benchmark_suite.tasks:  # iterate over all tasks\n",
    "\n",
    "    task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "    openml.config.apikey = '204cdba18d110fd68ad24b131ea92030'  # set the OpenML Api Key\n",
    "    run = openml.runs.run_model_on_task(clf, task)  # run the classifier on the task\n",
    "    score = run.get_metric_fn(sklearn.metrics.accuracy_score)  # print accuracy score\n",
    "    print('Data set: %s; Accuracy: %0.2f' % (task.get_dataset().name,score.mean()))\n",
    "#     run.publish()  # publish the experiment on OpenML (optional, requires internet and an API key)\n",
    "#     print('URL for run: %s/run/%d' %(openml.config.server,run.run_id))\n",
    "\n",
    "runs = openml.runs.list_runs(task=benchmark_suite.tasks, limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set: kr-vs-kp; Accuracy: 0.98\n",
      "Data set: letter; Accuracy: 0.94\n",
      "Data set: balance-scale; Accuracy: 0.83\n",
      "Data set: mfeat-factors; Accuracy: 0.95\n",
      "Data set: mfeat-fourier; Accuracy: 0.80\n",
      "Data set: breast-w; Accuracy: 0.96\n",
      "Data set: mfeat-karhunen; Accuracy: 0.91\n",
      "Data set: mfeat-morphological; Accuracy: 0.69\n",
      "Data set: mfeat-zernike; Accuracy: 0.75\n",
      "Data set: cmc; Accuracy: 0.51\n",
      "Data set: optdigits; Accuracy: 0.96\n",
      "Data set: credit-approval; Accuracy: 0.86\n",
      "Data set: credit-g; Accuracy: 0.75\n",
      "Data set: pendigits; Accuracy: 0.99\n",
      "Data set: diabetes; Accuracy: 0.74\n",
      "Data set: spambase; Accuracy: 0.94\n",
      "Data set: splice; Accuracy: 0.93\n",
      "Data set: tic-tac-toe; Accuracy: 0.93\n",
      "Data set: vehicle; Accuracy: 0.73\n",
      "Data set: electricity; Accuracy: 0.89\n",
      "Data set: satimage; Accuracy: 0.90\n",
      "Data set: eucalyptus; Accuracy: 0.64\n",
      "Data set: sick; Accuracy: 0.98\n",
      "Data set: vowel; Accuracy: 0.93\n",
      "Data set: isolet; Accuracy: 0.90\n",
      "Data set: analcatdata_authorship; Accuracy: 0.98\n",
      "Data set: analcatdata_dmft; Accuracy: 0.21\n",
      "Data set: mnist_784; Accuracy: 0.95\n",
      "Data set: pc4; Accuracy: 0.90\n",
      "Data set: pc3; Accuracy: 0.90\n",
      "Data set: jm1; Accuracy: 0.81\n",
      "Data set: kc2; Accuracy: 0.83\n",
      "Data set: kc1; Accuracy: 0.84\n",
      "Data set: pc1; Accuracy: 0.93\n",
      "Data set: adult; Accuracy: 0.85\n",
      "Data set: Bioresponse; Accuracy: 0.76\n",
      "Data set: wdbc; Accuracy: 0.96\n",
      "Data set: phoneme; Accuracy: 0.90\n",
      "Data set: qsar-biodeg; Accuracy: 0.86\n",
      "Data set: wall-robot-navigation; Accuracy: 0.99\n",
      "Data set: semeion; Accuracy: 0.87\n",
      "Data set: ilpd; Accuracy: 0.70\n",
      "Data set: madelon; Accuracy: 0.64\n",
      "Data set: nomao; Accuracy: 0.97\n",
      "Data set: ozone-level-8hr; Accuracy: 0.94\n",
      "Data set: cnae-9; Accuracy: 0.90\n",
      "Data set: first-order-theorem-proving; Accuracy: 0.60\n",
      "Data set: banknote-authentication; Accuracy: 1.00\n",
      "Data set: blood-transfusion-service-center; Accuracy: 0.75\n",
      "Data set: PhishingWebsites; Accuracy: 0.97\n",
      "Data set: cylinder-bands; Accuracy: 0.81\n",
      "Data set: bank-marketing; Accuracy: 0.90\n",
      "Data set: GesturePhaseSegmentationProcessed; Accuracy: 0.61\n",
      "Data set: har; Accuracy: 0.97\n",
      "Data set: dresses-sales; Accuracy: 0.54\n",
      "Data set: texture; Accuracy: 0.97\n",
      "Data set: connect-4; Accuracy: 0.79\n",
      "Data set: MiceProtein; Accuracy: 0.96\n",
      "Data set: steel-plates-fault; Accuracy: 0.76\n",
      "Data set: climate-model-simulation-crashes; Accuracy: 0.93\n",
      "Data set: wilt; Accuracy: 0.98\n",
      "Data set: car; Accuracy: 0.97\n",
      "Data set: segment; Accuracy: 0.93\n",
      "Data set: mfeat-pixel; Accuracy: 0.96\n",
      "Data set: Fashion-MNIST; Accuracy: 0.86\n",
      "Data set: jungle_chess_2pcs_raw_endgame_complete; Accuracy: 0.78\n",
      "Data set: numerai28.6; Accuracy: 0.50\n",
      "Data set: Devnagari-Script; Accuracy: 0.80\n"
     ]
    }
   ],
   "source": [
    "import openml\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#openml.config.apikey = 'c9ea8896542dd998ea42685f14e2bc14'  # set the OpenML Api Key\n",
    "benchmark_suite = openml.study.get_suite('OpenML-CC18')  # obtain the benchmark suite\n",
    "\n",
    "# build a scikit-learn classifier\n",
    "clf = sklearn.pipeline.make_pipeline(sklearn.preprocessing.Imputer(),\n",
    "                                     sklearn.ensemble.RandomForestClassifier())\n",
    "\n",
    "for task_id in benchmark_suite.tasks:  # iterate over all tasks\n",
    "\n",
    "    task = openml.tasks.get_task(task_id) # download the OpenML task\n",
    "    #X, y = task.get_X_and_y() # get the data (not used in this example)\n",
    "    openml.config.apikey = 'c9ea8896542dd998ea42685f14e2bc14'  # set the OpenML Api Key\n",
    "    run = openml.runs.run_model_on_task(clf, task) # run classifier on splits (requires API key)\n",
    "    score = run.get_metric_fn(sklearn.metrics.accuracy_score) # print accuracy score\n",
    "    print('Data set: %s; Accuracy: %0.2f' % (task.get_dataset().name,score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tealeaf] *",
   "language": "python",
   "name": "conda-env-tealeaf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
