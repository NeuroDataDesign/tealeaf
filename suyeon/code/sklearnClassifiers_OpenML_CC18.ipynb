{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "benchmark_suite = openml.study.get_suite('OpenML-CC18')  # obtain the benchmark suite\n",
    "\n",
    "# build a scikit-learn classifier\n",
    "clf = sklearn.pipeline.make_pipeline(sklearn.preprocessing.Imputer(), DecisionTreeClassifier())\n",
    "\n",
    "for task_id in benchmark_suite.tasks:  # iterate over all tasks\n",
    "\n",
    "    task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "    openml.config.apikey = '204cdba18d110fd68ad24b131ea92030'  # set the OpenML Api Key\n",
    "    run = openml.runs.run_model_on_task(clf, task)  # run the classifier on the task\n",
    "    score = run.get_metric_fn(sklearn.metrics.accuracy_score)  # print accuracy score\n",
    "    print('Data set: %s; Accuracy: %0.2f' % (task.get_dataset().name,score.mean()))\n",
    "#     run.publish()  # publish the experiment on OpenML (optional, requires internet and an API key)\n",
    "#     print('URL for run: %s/run/%d' %(openml.config.server,run.run_id))\n",
    "\n",
    "runs = openml.runs.list_runs(task=benchmark_suite.tasks, limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#openml.config.apikey = 'c9ea8896542dd998ea42685f14e2bc14'  # set the OpenML Api Key\n",
    "benchmark_suite = openml.study.get_suite('OpenML-CC18')  # obtain the benchmark suite\n",
    "\n",
    "# build a scikit-learn classifier\n",
    "clf = sklearn.pipeline.make_pipeline(sklearn.preprocessing.Imputer(),\n",
    "                                     sklearn.ensemble.RandomForestClassifier())\n",
    "\n",
    "for task_id in benchmark_suite.tasks:  # iterate over all tasks\n",
    "\n",
    "    task = openml.tasks.get_task(task_id) # download the OpenML task\n",
    "    #X, y = task.get_X_and_y() # get the data (not used in this example)\n",
    "    openml.config.apikey = 'c9ea8896542dd998ea42685f14e2bc14'  # set the OpenML Api Key\n",
    "    run = openml.runs.run_model_on_task(clf, task) # run classifier on splits (requires API key)\n",
    "    score = run.get_metric_fn(sklearn.metrics.accuracy_score) # print accuracy score\n",
    "    print('Data set: %s; Accuracy: %0.2f' % (task.get_dataset().name,score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tealeaf] *",
   "language": "python",
   "name": "conda-env-tealeaf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
